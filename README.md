# DeepHat - AI Agent for Cybersecurity & DevOps

An intelligent AI assistant powered by LangGraph and the DeepHat model, specialized in cybersecurity and DevOps tasks with autonomous tool calling capabilities.

## ğŸ—ï¸ Architecture

```
User Browser
     â†“
Next.js Frontend (Port 3000)
     â†“ HTTP/SSE
Python Backend (Port 8000)
     â†“ LangGraph Agent + Tools
HuggingFace API (DeepHat Model)
```

**Key Feature**: Frontend exclusively communicates with Python backend - no direct HuggingFace API calls from the browser.

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ and pnpm
- Python 3.8+
- HuggingFace API key

### 1. Start Backend

```bash
cd backend
./dev.sh
```

Backend will start on http://localhost:8000

### 2. Start Frontend

```bash
cd frontend
pnpm install
pnpm dev
```

Frontend will start on http://localhost:3000

### 3. Test Integration

```bash
./test-integration.sh
```

## ğŸ”§ Configuration

### Backend (`backend/.env`)
```env
HUGGINGFACE_API_KEY=your_key_here
HUGGINGFACE_MODEL=DeepHat/DeepHat-V1-7B
PORT=8000
```

### Frontend (`frontend/.env`)
```env
PYTHON_BACKEND_URL=http://localhost:8000
```

## ğŸ› ï¸ Features

### AI Agent Capabilities
- **Autonomous Tool Calling**: Agent decides when to use tools
- **Security Scanning**: Vulnerability assessment
- **System Monitoring**: Service status checks
- **Log Analysis**: Error detection and analysis
- **Configuration Deployment**: Automated deployments

### Technical Features
- **Hot Reload**: Both frontend and backend support live reloading
- **Streaming Responses**: Real-time SSE streaming
- **Retry Logic**: Automatic retry for model loading
- **Error Handling**: User-friendly error messages
- **API Documentation**: Interactive docs at `/docs`

## ğŸ“š Documentation

- **[SETUP.md](frontend/SETUP.md)** - Detailed setup instructions
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System architecture details
- **[backend/README.md](backend/README.md)** - Backend documentation

## ğŸ§ª Testing

### Test Backend Directly
```bash
# Health check
curl http://localhost:8000/health

# Chat request
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Scan my web application"}'
```

### Test Full Integration
```bash
./test-integration.sh
```

## ğŸ” Security

- âœ… API keys stored only in backend
- âœ… Frontend never accesses HuggingFace directly
- âœ… CORS protection enabled
- âœ… Environment variables for sensitive data

## ğŸ¯ Example Queries

Try these to see the agent in action:

- "Scan my web application for vulnerabilities"
- "Check the status of the nginx service"
- "Analyze the application logs for errors"
- "Deploy the production config to staging environment"

## ğŸ› ï¸ Development

### Adding New Tools

Edit `backend/agent.py`:

```python
TOOLS = {
    "your_tool": {
        "description": "What your tool does",
        "parameters": ["param1"],
        "function": lambda param1: f"Result: {param1}"
    }
}
```

### Project Structure

```
cmatrix/
â”œâ”€â”€ frontend/              # Next.js app
â”‚   â”œâ”€â”€ app/api/chat/     # API route (proxies to backend)
â”‚   â””â”€â”€ .env              # Frontend config
â”œâ”€â”€ backend/              # Python app
â”‚   â”œâ”€â”€ app.py           # FastAPI server
â”‚   â”œâ”€â”€ agent.py         # LangGraph agent
â”‚   â””â”€â”€ .env             # Backend config (API keys)
â”œâ”€â”€ ARCHITECTURE.md      # Architecture details
â””â”€â”€ README.md           # This file
```

## ğŸ› Troubleshooting

### "Cannot connect to Python backend"
- Ensure backend is running: `cd backend && ./dev.sh`
- Check: `curl http://localhost:8000/health`

### "Model is loading"
- First request takes 15-30 seconds (cold start)
- Backend automatically retries
- Subsequent requests are fast

### Port conflicts
```bash
# Kill process on port 8000
lsof -ti:8000 | xargs kill -9

# Kill process on port 3000
lsof -ti:3000 | xargs kill -9
```

## ğŸ“Š API Endpoints

### Backend (Port 8000)
- `GET /` - API info
- `GET /health` - Health check
- `POST /chat` - Non-streaming chat
- `POST /chat/stream` - Streaming chat
- `GET /docs` - Interactive API docs

### Frontend (Port 3000)
- `POST /api/chat` - Chat endpoint (proxies to backend)

## ğŸŒŸ Tech Stack

- **Frontend**: Next.js 16, React 19, TypeScript
- **Backend**: FastAPI, Python 3.11
- **AI Framework**: LangGraph, LangChain
- **Model**: DeepHat-V1-7B (via HuggingFace)
- **Streaming**: Server-Sent Events (SSE)

## ğŸ“ License

This project is for educational and development purposes.

## ğŸ¤ Contributing

1. Add new tools in `backend/agent.py`
2. Update frontend UI as needed
3. Test with `./test-integration.sh`
4. Document changes

## ğŸ”— Links

- **Backend API Docs**: http://localhost:8000/docs
- **Frontend**: http://localhost:3000
- **HuggingFace Model**: DeepHat/DeepHat-V1-7B

---

Built with â¤ï¸ using LangGraph, FastAPI, and Next.js
